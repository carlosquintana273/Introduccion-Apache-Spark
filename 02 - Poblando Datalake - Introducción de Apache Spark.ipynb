{"cells":[{"cell_type":"markdown","metadata":{},"source":["# POBLANDO DATALAKE - INTRODUCCIÓN APACHE SPARK"]},{"cell_type":"markdown","metadata":{},"source":["## POBLANDO CAPA LANDING\n","**1° PASO** Importamos módulos de apache spark"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *"]},{"cell_type":"markdown","metadata":{},"source":["**2° PASO** Creamos las session de apache spark en una variable"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"]},{"cell_type":"markdown","metadata":{},"source":["**3° PASO** Verificamos la versión de apache spark"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-1b8d-m.us-central1-c.c.dark-diagram-322105.internal:34977\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v2.4.8</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fc6c4515cd0>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"markdown","metadata":{},"source":["### CAPA LANDING - PERSONAS\n","\n","**4° PASO** Crear un dataframe\n","\n","* Crear la estructura del dataframe\n","* Declarar en una variable la ruta del archivo\n","* Leer el archivo de origen\n","* Mostrar la estructura del dataframe\n","* mostrar los datos del dataframe\n","* Cantidad de registros del dataframe\n","* Mostrar las estadísticas básicas de un campo determinado"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["# 4.1 Estructura del dataframe.\n","df_schema = StructType([\n","StructField(\"ID\", StringType(),True),\n","StructField(\"NOMBRE\", StringType(),True),\n","StructField(\"TELEFONO\", StringType(),True),\n","StructField(\"CORREO\", StringType(),True),\n","StructField(\"FECHA_INGRESO\", StringType(),True),\n","StructField(\"EDAD\", IntegerType(),True),\n","StructField(\"SALARIO\", DoubleType(),True),\n","StructField(\"ID_EMPRESA\", StringType(),True),\n","])\n","\n"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["# 4.2 Definimos ruta del archivo\n","\n","ruta_archivo_google_cloud = \"gs://introduccion-apache-spark/datalake/workload/personas/persona.data\"\n","\n","ruta_archivo_databricks = \"/introduccion-apache-spark/datalake/workload/personas/persona.data\"\n","\n","ruta_archivo_hdfs = \"hdfs:/introduccion-apache-spark/datalake/workload/personas/persona.data\"\n"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["#4.3 Definimos ruta del archivo\n","df_personas = spark.read.format(\"CSV\").option(\"header\",\"true\").option(\"delimiter\",\"|\").schema(df_schema).load(ruta_archivo_google_cloud)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- ID: string (nullable = true)\n"," |-- NOMBRE: string (nullable = true)\n"," |-- TELEFONO: string (nullable = true)\n"," |-- CORREO: string (nullable = true)\n"," |-- FECHA_INGRESO: string (nullable = true)\n"," |-- EDAD: integer (nullable = true)\n"," |-- SALARIO: double (nullable = true)\n"," |-- ID_EMPRESA: string (nullable = true)\n","\n"]}],"source":["#4.4 Mostramos la estructura del dataframe.\n","df_personas.printSchema()"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|      TELEFONO|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|1-745-633-9145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|      155-2498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|1-204-956-8594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|1-719-862-9385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|      839-8044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","only showing top 5 rows\n","\n"]}],"source":["# 4.5 Mostraremos todos los datos del dataframe.\n","df_personas.show(5)"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["La cantidad de registro del dataframe es:  100\n"]}],"source":["# 4.6 Mostraremos todos los datos del dataframe.\n","num_rows = df_personas.count()\n","\n","print(\"La cantidad de registro del dataframe es: \", num_rows)"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------------+\n","|summary|          salario|\n","+-------+-----------------+\n","|  count|              100|\n","|   mean|         11684.55|\n","| stddev|6841.493958437246|\n","|    min|           1256.0|\n","|    max|          24575.0|\n","+-------+-----------------+\n","\n"]}],"source":["# 4.7 Estadísticas de un campo determinado.\n","df_personas.describe('salario').show()"]},{"cell_type":"markdown","metadata":{},"source":["**5° PASO** Guardar el dataframe en un ruta de la capa landing"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["ruta_destino_google_cloud = \"gs://introduccion-apache-spark/datalake/landing/personas/\"\n","\n","ruta_destino_databricks = \"/content/datalake/landing/personas.parquet\"\n","\n","ruta_destino_hdfs = \"hdfs:/introduccion-apache-spark/datalake/landing/personas/\""]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["df_personas.write.mode(\"overwrite\").format(\"parquet\").save(ruta_destino_google_cloud)"]},{"cell_type":"markdown","metadata":{},"source":["### CAPA LANDING -  EMPRESAS \n","**6° PASO** Realizar la ingesta de Empresas en la capa landing\n","* Crear estructura del dataframe.\n","* Definir la ruta del archivo.\n","* Crear la estructura del dataframe\n","* Declarar en una variable la ruta del archivo\n","* Leer el archivo de origen\n","* Mostrar la información del dataframe\n","* Guardar el dataframe en un ruta de la capa landing"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["# 6.1 Estructura del dataframe.\n","df_schema_empresas = StructType([\n","StructField(\"ID\", StringType(),True),\n","StructField(\"EMPRESA_NAME\", StringType(),True)\n","])"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["# 6.2 Definimos ruta del archivo\n","\n","ruta_archivo_google_cloud = \"gs://introduccion-apache-spark/datalake/workload/empresas/empresa.data\"\n","\n","ruta_archivo_databricks = \"/introduccion-apache-spark/datalake/workload/empresas/empresa.data\"\n","\n","ruta_archivo_hdfs = \"hdfs:/introduccion-apache-spark/datalake/workload/empresas/empresa.data\""]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["# 6.3 Creamos el dataframe \n","df_empresas = spark.read.format(\"CSV\").option(\"header\",\"true\").option(\"delimiter\",\"|\").schema(df_schema_empresas).load(ruta_archivo_google_cloud)"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  1|     Walmart|\n","|  2|   Microsoft|\n","|  3|       Apple|\n","|  4|      Toyota|\n","|  5|      Amazon|\n","|  6|      Google|\n","|  7|     Samsung|\n","|  8|          HP|\n","|  9|         IBM|\n","| 10|        Sony|\n","+---+------------+\n","\n"]}],"source":["# 6.4 Mostramos registros del dataframe\n","df_empresas.show(10)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["# 6.5 Definimos la ruta de almacenamiento\n","\n","ruta_destino_google_cloud = \"gs://introduccion-apache-spark/datalake/landing/empresas/\"\n","\n","ruta_destino_databricks = \"/introduccion-apache-spark/datalake/landing/empresas/\"\n","\n","ruta_destino_hdfs = \"hdfs:/introduccion-apache-spark/datalake/landing/empresas/\"\n"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["# 6.6 Guardamos el archivo en formato parquet\n","df_empresas.repartition(2).write.mode(\"overwrite\").format(\"parquet\").save(ruta_destino_google_cloud)"]},{"cell_type":"markdown","metadata":{},"source":["## POBLANDO CAPA CURATED"]},{"cell_type":"markdown","metadata":{},"source":["### PERSONAS\n","**7° PASO** Definimos ruta del archivo"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["ruta_landing_google_cloud = \"gs://introduccion-apache-spark/datalake/landing/personas/\"\n","\n","ruta_landing_databricks = \"/introduccion-apache-spark/datalake/landing/personas/\"\n","\n","ruta_landing_hdfs = \"hdfs:/introduccion-apache-spark/datalake/landing/personas/\""]},{"cell_type":"markdown","metadata":{},"source":["**8° PASO** Creamos el dataframe de Persona"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["df_personas_landing = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_landing_google_cloud)"]},{"cell_type":"markdown","metadata":{},"source":["**9° PASO** Mostramos el dataframe cargado en memoria"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|      TELEFONO|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|1-745-633-9145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|      155-2498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|1-204-956-8594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|1-719-862-9385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|      839-8044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","|  6|     Bert|      797-4453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|\n","|  7|     Mark|1-680-102-6792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|\n","|  8|    Jonah|      214-2975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|\n","|  9|    Hanae|      935-2277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|\n","| 10|   Cadman|1-866-561-2701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","only showing top 10 rows\n","\n"]}],"source":["df_personas_landing.show(10)"]},{"cell_type":"markdown","metadata":{},"source":["**10° PASO** Mostramos el schema del dataframe"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- ID: string (nullable = true)\n"," |-- NOMBRE: string (nullable = true)\n"," |-- TELEFONO: string (nullable = true)\n"," |-- CORREO: string (nullable = true)\n"," |-- FECHA_INGRESO: string (nullable = true)\n"," |-- EDAD: integer (nullable = true)\n"," |-- SALARIO: double (nullable = true)\n"," |-- ID_EMPRESA: string (nullable = true)\n","\n"]}],"source":["df_personas_landing.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["**11° PASO** Realizamos la limpieza del dataframe"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","|  6|     Bert|    7974453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|\n","|  7|     Mark|16801026792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|\n","|  8|    Jonah|    2142975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|\n","|  9|    Hanae|    9352277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|\n","| 10|   Cadman|18665612701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","only showing top 10 rows\n","\n"]}],"source":["df_personas_procesado = df_personas_landing.withColumn('telefono', regexp_replace('telefono', '-', ''))\n","df_personas_procesado.show(10)"]},{"cell_type":"markdown","metadata":{},"source":["**12° PASO** Definir ruta de almacenamiento en la capa curated"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["ruta_curated_personas_google_cloud = \"gs://introduccion-apache-spark/datalake/curated/personas/\"\n","\n","ruta_curated_personas_databricks = \"/introduccion-apache-spark/datalake/curated/personas/\"\n","\n","ruta_curated_personas_hdfs = \"hdfs:/introduccion-apache-spark/datalake/curated/personas/\"\n"]},{"cell_type":"markdown","metadata":{},"source":["**13° PASO** Definir ruta de almacenamiento en la capa curated"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[],"source":["df_personas_procesado.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_curated_personas_google_cloud)"]},{"cell_type":"markdown","metadata":{},"source":["### EMPRESAS\n","**14° PASO** Realizar la ingesta de Empresas en Curated\n","\n","* Declarar en una variable la ruta del archivo\n","* Leer el archivo de la capa landing\n","* Mostrar la estructura del dataframe\n","* mostrar los datos del dataframe\n","* Realizar una limpieza al dataframe\n","* Guardar el dataframe en un ruta de la capa curated"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- ID: string (nullable = true)\n"," |-- EMPRESA_NAME: string (nullable = true)\n","\n","+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  5|      Amazon|\n","|  6|      Google|\n","|  4|      Toyota|\n","|  7|     Samsung|\n","|  3|       Apple|\n","+---+------------+\n","only showing top 5 rows\n","\n","+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  5|      AMAZON|\n","|  6|      GOOGLE|\n","|  4|      TOYOTA|\n","|  7|     SAMSUNG|\n","|  3|       APPLE|\n","+---+------------+\n","only showing top 5 rows\n","\n"]}],"source":["# 14.1 variable la ruta del archivo\n","ruta_landing_empresas_google_cloud = \"gs://introduccion-apache-spark/datalake/landing/empresas/\"\n","\n","ruta_landing_empresas_databricks = \"/introduccion-apache-spark/datalake/landing/empresas/\"\n","\n","ruta_landing_empresas_hdfs = \"hdfs:/introduccion-apache-spark/datalake/landing/empresas/\"\n","\n","# 14.2 Leer el archivo de la capa landing\n","df_empresas_landing = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_landing_empresas_google_cloud)\n","\n","# 14.3 Mostrar la estructura del dataframe\n","df_empresas_landing.printSchema()\n","\n","#14.4 Mostrar los datos del dataframe\n","df_empresas_landing.show(5)\n","\n","#14.5 Realizar limpieza a dataframe\n","df_empresas_procesado = df_empresas_landing.withColumn('EMPRESA_NAME',upper(col('EMPRESA_NAME')))\n","\n","#14.6 Mostrar los datos procesado\n","df_empresas_procesado.show(5)\n","\n","#14. Definir ruta de curated\n","ruta_curated_empresas_google_cloud = \"gs://introduccion-apache-spark/datalake/curated/empresas/\"\n","\n","ruta_curated_empresas_databricks = \"/introduccion-apache-spark/datalake/curated/empresas/\"\n","\n","ruta_curated_empresas_hdfs = \"hdfs:/introduccion-apache-spark/datalake/curated/empresas/\"\n","\n","# 14.6 Guardar daframe en capa curated\n","\n","df_empresas_procesado.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_curated_empresas_google_cloud)\n"]},{"cell_type":"markdown","metadata":{},"source":["## POBLANDO CAPA FUNCTIONAL"]},{"cell_type":"markdown","metadata":{},"source":["**PASO 15°** Obteniendo información requeridad para el analisis de **Salario x Empresa**"]},{"cell_type":"markdown","metadata":{},"source":["**15.1** Definimos ruta tablas requeridas apuntando a la capa curated "]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["ruta_curated_empresas_google_cloud = \"gs://introduccion-apache-spark/datalake/curated/empresas/\"\n","\n","ruta_curated_personas_google_cloud = \"gs://introduccion-apache-spark/datalake/curated/personas/\""]},{"cell_type":"markdown","metadata":{},"source":["**15.2** Creamos el dataframe para cada tabla."]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["df_personas_curated = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_curated_personas_google_cloud)\n","\n","df_empresas_curated = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_curated_empresas_google_cloud)"]},{"cell_type":"markdown","metadata":{},"source":["**15.3** Mostramos datos de los dataframes"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","only showing top 5 rows\n","\n","+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  5|      AMAZON|\n","|  6|      GOOGLE|\n","|  4|      TOYOTA|\n","|  7|     SAMSUNG|\n","|  3|       APPLE|\n","+---+------------+\n","only showing top 5 rows\n","\n"]}],"source":["df_personas_curated.show(5)\n","df_empresas_curated.show(5)"]},{"cell_type":"markdown","metadata":{},"source":["**15.4** Realizar la unión (join) de ambas tablas "]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA| ID|EMPRESA_NAME|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|  5|      AMAZON|\n","|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|  2|   MICROSOFT|\n","|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|  3|       APPLE|\n","|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10| 10|        SONY|\n","|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|  1|     WALMART|\n","|  6|     Bert|    7974453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|  7|     SAMSUNG|\n","|  7|     Mark|16801026792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|  5|      AMAZON|\n","|  8|    Jonah|    2142975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|  5|      AMAZON|\n","|  9|    Hanae|    9352277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|  3|       APPLE|\n","| 10|   Cadman|18665612701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|  7|     SAMSUNG|\n","| 11|  Melyssa|    5967736|vel@vulputateposu...|   2008-10-14|  48| 4913.0|         8|  8|          HP|\n","| 12|   Tanner|17397767897|arcu.Aliquam.ultr...|   2011-05-10|  24|19943.0|         8|  8|          HP|\n","| 13|   Trevor|    5121955|Nunc.quis.arcu@eg...|   2010-08-06|  34| 9501.0|         5|  5|      AMAZON|\n","| 14|    Allen|    7332795|felis.Donec@necle...|   2005-03-07|  59|16289.0|         2|  2|   MICROSOFT|\n","| 15|    Wanda|    3596973|Nam.nulla.magna@I...|   2005-08-21|  27| 1539.0|         5|  5|      AMAZON|\n","| 16|    Alden|    3418522|odio@morbitristiq...|   2006-12-05|  26| 3377.0|         2|  2|   MICROSOFT|\n","| 17|     Omar|    7201543|Phasellus.vitae.m...|   2014-06-24|  60| 6851.0|         6|  6|      GOOGLE|\n","| 18|     Owen|11673357541|     sociis@erat.com|   2002-04-09|  34| 4759.0|         7|  7|     SAMSUNG|\n","| 19|    Laura|19746232057|    mollis@ornare.ca|   2017-03-09|  70|17403.0|         4|  4|      TOYOTA|\n","| 20|    Emery|16728400264|     at.nisi@vel.org|   2004-02-27|  24|18752.0|         9|  9|         IBM|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","only showing top 20 rows\n","\n"]}],"source":["df_join = df_personas_curated.join(df_empresas_curated, df_personas_curated.ID_EMPRESA == df_empresas_curated.ID)\n","df_join.show()"]},{"cell_type":"markdown","metadata":{},"source":["**15.5**  Realizar la unión (join) de ambas tablas utilizando **Spark SQL**"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA| ID|EMPRESA_NAME|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|  5|      AMAZON|\n","|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|  2|   MICROSOFT|\n","|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|  3|       APPLE|\n","|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10| 10|        SONY|\n","|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|  1|     WALMART|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+---+------------+\n","only showing top 5 rows\n","\n"]}],"source":["df_personas_curated.createOrReplaceTempView(\"tb_personas\")\n","df_empresas_curated.createOrReplaceTempView(\"tb_empresas\")\n","\n","df_sql = spark.sql(\"SELECT * FROM tb_personas p inner join tb_empresas e on e.ID = p.ID_EMPRESA\")\n","df_sql.show(5)"]},{"cell_type":"markdown","metadata":{},"source":["**15.6** Seleccionar campos requeridos para el análisis "]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----+-------+------------+\n","|EDAD|SALARIO|EMPRESA_NAME|\n","+----+-------+------------+\n","|  32|20095.0|      AMAZON|\n","|  34| 9298.0|   MICROSOFT|\n","|  27|10853.0|       APPLE|\n","|  29| 3387.0|        SONY|\n","|  41|22102.0|     WALMART|\n","|  70| 7800.0|     SAMSUNG|\n","|  52| 8112.0|      AMAZON|\n","|  23|17040.0|      AMAZON|\n","|  69| 6834.0|       APPLE|\n","|  19| 7996.0|     SAMSUNG|\n","|  48| 4913.0|          HP|\n","|  24|19943.0|          HP|\n","|  34| 9501.0|      AMAZON|\n","|  59|16289.0|   MICROSOFT|\n","|  27| 1539.0|      AMAZON|\n","|  26| 3377.0|   MICROSOFT|\n","|  60| 6851.0|      GOOGLE|\n","|  34| 4759.0|     SAMSUNG|\n","|  70|17403.0|      TOYOTA|\n","|  24|18752.0|         IBM|\n","+----+-------+------------+\n","only showing top 20 rows\n","\n"]}],"source":["df_select = df_join.select(col('EDAD'),col('SALARIO'),col('EMPRESA_NAME'))\n","df_select.show()"]},{"cell_type":"markdown","metadata":{},"source":["**15.7** Definimos la ruta de functional y persistimos los registros"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["ruta_functional = \"gs://introduccion-apache-spark/datalake/functional/salario_empresa/\"\n","\n","df_select.repartition(1).write.mode(\"overwrite\").format(\"parquet\").save(ruta_functional)"]},{"cell_type":"markdown","metadata":{},"source":["**15.8** Consultamos la información almacenada en Funcional"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----+-------+------------+\n","|EDAD|SALARIO|EMPRESA_NAME|\n","+----+-------+------------+\n","|  32|20095.0|      AMAZON|\n","|  34| 9298.0|   MICROSOFT|\n","|  27|10853.0|       APPLE|\n","|  29| 3387.0|        SONY|\n","|  41|22102.0|     WALMART|\n","|  70| 7800.0|     SAMSUNG|\n","|  52| 8112.0|      AMAZON|\n","|  23|17040.0|      AMAZON|\n","|  69| 6834.0|       APPLE|\n","|  19| 7996.0|     SAMSUNG|\n","+----+-------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["df_salario_empresa = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_functional)\n","df_salario_empresa.show(10)"]},{"cell_type":"markdown","metadata":{},"source":["\n","# Felicitaciones por completar el curso de Introducción Apache Spark\n","#### **Elaborado por** Juan Salinas\n","#### Linkedin: https://www.linkedin.com/in/juan-salinas/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":2}