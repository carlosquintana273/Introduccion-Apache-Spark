{"cells":[{"cell_type":"markdown","id":"502236b1","metadata":{},"source":["# Poblando Capa Curated\n","\n","### Poblando Clientes\n","\n","**1° PASO:** Importamos módulos de apache spark"]},{"cell_type":"code","execution_count":14,"id":"893a4188","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *"]},{"cell_type":"code","execution_count":4,"id":"c182ef61","metadata":{},"outputs":[],"source":["spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"markdown","id":"b62fbc33","metadata":{},"source":["**8° PASO** Definimos ruta del archivo de la capa previa"]},{"cell_type":"code","execution_count":16,"id":"d520c4fd","metadata":{},"outputs":[],"source":["#Archivo en Cloud Storage - Google Cloud Platform\n","ruta_persona_landing = \"gs://curso-apache-spark/datalake/landing/personas/\"\n","\n","#Archivo DBFS - DataBricks\n","# ruta_persona_landing = \"/FileStore/tables/landing/personas/\"\n","\n","\n","#Archivo en HDFS - Hadoop\n","#ruta_persona_landing = \"hdfs:/introduccion-apache-spark/datalake/landing/personas/\"\n","\n","df_personas_landing = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_persona_landing)"]},{"cell_type":"markdown","id":"026ebaba","metadata":{},"source":["**9° PASO** Mostramos el dataframe cargado en memoria"]},{"cell_type":"code","execution_count":8,"id":"1275a23c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 1:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|      TELEFONO|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|1-745-633-9145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|      155-2498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|1-204-956-8594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|1-719-862-9385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|      839-8044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","|  6|     Bert|      797-4453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|\n","|  7|     Mark|1-680-102-6792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|\n","|  8|    Jonah|      214-2975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|\n","|  9|    Hanae|      935-2277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|\n","| 10|   Cadman|1-866-561-2701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|\n","+---+---------+--------------+--------------------+-------------+----+-------+----------+\n","only showing top 10 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df_personas_landing.show(10)"]},{"cell_type":"markdown","id":"807ba2f0","metadata":{},"source":["**10° PASO** Mostramos el schema del dataframe"]},{"cell_type":"code","execution_count":9,"id":"c74a5a45","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- ID: string (nullable = true)\n"," |-- NOMBRE: string (nullable = true)\n"," |-- TELEFONO: string (nullable = true)\n"," |-- CORREO: string (nullable = true)\n"," |-- FECHA_INGRESO: string (nullable = true)\n"," |-- EDAD: integer (nullable = true)\n"," |-- SALARIO: double (nullable = true)\n"," |-- ID_EMPRESA: string (nullable = true)\n","\n"]}],"source":["df_personas_landing.printSchema()"]},{"cell_type":"markdown","id":"8dd7698e","metadata":{},"source":["**11° PASO** Realizamos la limpieza del dataframe"]},{"cell_type":"code","execution_count":15,"id":"faa14b07","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","| ID|   NOMBRE|   telefono|              CORREO|FECHA_INGRESO|EDAD|SALARIO|ID_EMPRESA|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","|  1|     Carl|17456339145|arcu.Sed.et@ante....|   2004-04-23|  32|20095.0|         5|\n","|  2|Priscilla|    1552498|Donec.egestas.Ali...|   2019-02-17|  34| 9298.0|         2|\n","|  3|  Jocelyn|12049568594|amet.diam@loborti...|   2002-08-01|  27|10853.0|         3|\n","|  4|    Aidan|17198629385|euismod.et.commod...|   2018-11-06|  29| 3387.0|        10|\n","|  5|  Leandra|    8398044|at@pretiumetrutru...|   2002-10-10|  41|22102.0|         1|\n","|  6|     Bert|    7974453|a.felis.ullamcorp...|   2017-04-25|  70| 7800.0|         7|\n","|  7|     Mark|16801026792|Quisque.ac@placer...|   2006-04-21|  52| 8112.0|         5|\n","|  8|    Jonah|    2142975|eu.ultrices.sit@v...|   2017-10-07|  23|17040.0|         5|\n","|  9|    Hanae|    9352277|          eu@Nunc.ca|   2003-05-25|  69| 6834.0|         3|\n","| 10|   Cadman|18665612701|orci.adipiscing.n...|   2001-05-19|  19| 7996.0|         7|\n","+---+---------+-----------+--------------------+-------------+----+-------+----------+\n","only showing top 10 rows\n","\n"]}],"source":["df_personas_procesado = df_personas_landing.withColumn('telefono', regexp_replace('telefono', '-', ''))\n","df_personas_procesado.show(10)"]},{"cell_type":"markdown","id":"59a17931","metadata":{},"source":["**12° PASO** Definir ruta de almacenamiento en la capa curated"]},{"cell_type":"code","execution_count":18,"id":"3bda4b1e","metadata":{},"outputs":[],"source":["#Archivo en Cloud Storage - Google Cloud Platform\n","ruta_persona_curated = \"gs://curso-apache-spark/datalake/curated/personas/\"\n","\n","#Archivo DBFS - DataBricks\n","# ruta_persona_curated = \"/FileStore/tables/curated/personas/\"\n","\n","\n","#Archivo en HDFS - Hadoop\n","#ruta_persona_curated = \"hdfs:/introduccion-apache-spark/datalake/curated/personas/\"\n","\n"]},{"cell_type":"code","execution_count":19,"id":"d5410b90","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df_personas_procesado.write.mode(\"overwrite\").format(\"parquet\").save(ruta_persona_curated)"]},{"cell_type":"markdown","id":"af92532c","metadata":{},"source":["### Poblando Empresa\n","**13° PASO** Poblando capa Curated empresa\n","\n","* Declarar en una variable la ruta del archivo\n","* Leer el archivo de la capa landing\n","* Mostrar la estructura del dataframe\n","* mostrar los datos del dataframe\n","* Realizar una limpieza al dataframe\n","* Guardar el dataframe en un ruta de la capa curated"]},{"cell_type":"code","execution_count":22,"id":"bcdeeddd","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- ID: string (nullable = true)\n"," |-- EMPRESA_NAME: string (nullable = true)\n","\n","+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  1|     Walmart|\n","|  2|   Microsoft|\n","|  3|       Apple|\n","|  4|      Toyota|\n","|  5|      Amazon|\n","+---+------------+\n","only showing top 5 rows\n","\n","+---+------------+\n","| ID|EMPRESA_NAME|\n","+---+------------+\n","|  1|     WALMART|\n","|  2|   MICROSOFT|\n","|  3|       APPLE|\n","|  4|      TOYOTA|\n","|  5|      AMAZON|\n","+---+------------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# 13.1 variable la ruta del archivo\n","\n","#Archivo en Cloud Storage - Google Cloud Platform\n","ruta_empresa_landing = \"gs://curso-apache-spark/datalake/landing/empresas/\"\n","\n","#Archivo DBFS - DataBricks\n","# ruta_empresa_landing = \"/FileStore/tables/landing/empresas/\"\n","\n","#Archivo en HDFS - Hadoop\n","#ruta_empresa_landing = \"hdfs:/introduccion-apache-spark/datalake/landing/empresas/\"\n","\n","\n","# 13.2 Leer el archivo de la capa landing\n","df_empresas_landing = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_empresa_landing)\n","\n","# 13.3 Mostrar la estructura del dataframe\n","df_empresas_landing.printSchema()\n","\n","#13.4 Mostrar los datos del dataframe\n","df_empresas_landing.show(5)\n","\n","#13.5 Realizar limpieza a dataframe\n","df_empresas_procesado = df_empresas_landing.withColumn('EMPRESA_NAME',upper(col('EMPRESA_NAME')))\n","\n","#13.6 Mostrar los datos procesado\n","df_empresas_procesado.show(5)\n","\n","#13.7 Definir ruta de curated\n","\n","#Archivo en Cloud Storage - Google Cloud Platform\n","ruta_empresa_curated = \"gs://curso-apache-spark/datalake/curated/empresas/\"\n","\n","#Archivo DBFS - DataBricks\n","# ruta_empresa_curated = \"/FileStore/tables/curated/empresas/\"\n","\n","#Archivo en HDFS - Hadoop\n","#ruta_empresa_curated = \"hdfs:/introduccion-apache-spark/datalake/curated/empresas/\"\n","\n","# 13.8 Guardar daframe en capa curated\n","\n","df_empresas_procesado.write.mode(\"overwrite\").format(\"parquet\").save(ruta_empresa_curated)"]},{"cell_type":"markdown","id":"22802694","metadata":{},"source":["### Poblando Transacciones\n","**14° PASO** Poblando capa Curated Transacciones\n","\n","* Declarar en una variable la ruta del archivo\n","* Leer el archivo de la capa landing\n","* Mostrar la estructura del dataframe\n","* mostrar los datos del dataframe\n","* Realizar una limpieza al dataframe\n","* Guardar el dataframe en un ruta de la capa curated"]},{"cell_type":"code","execution_count":25,"id":"0ce6cece","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- ID_PERSONA: string (nullable = true)\n"," |-- ID_EMPRESA: string (nullable = true)\n"," |-- MONTO: double (nullable = true)\n"," |-- FECHA: string (nullable = true)\n","\n","+----------+----------+------+----------+\n","|ID_PERSONA|ID_EMPRESA| MONTO|     FECHA|\n","+----------+----------+------+----------+\n","|        18|         3|1383.0|2018-01-21|\n","|        30|         6|2331.0|2018-01-21|\n","|        47|         2|2280.0|2018-01-21|\n","|        28|         1| 730.0|2018-01-21|\n","|        91|         4|3081.0|2018-01-21|\n","+----------+----------+------+----------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# 14.1 variable la ruta del archivo\n","\n","#Archivo en Cloud Storage - Google Cloud Platform\n","ruta_transacciones_landing = \"gs://curso-apache-spark/datalake/landing/transacciones/\"\n","\n","#Archivo DBFS - DataBricks\n","# ruta_transacciones_landing = \"/FileStore/tables/landing/transacciones/\"\n","\n","#Archivo en HDFS - Hadoop\n","#ruta_transacciones_landing = \"hdfs:/introduccion-apache-spark/datalake/landing/transacciones/\"\n","\n","\n","# 13.2 Leer el archivo de la capa landing\n","df_transacciones_landing = spark.read.format(\"parquet\").option(\"header\",\"true\").load(ruta_transacciones_landing)\n","\n","# 13.3 Mostrar la estructura del dataframe\n","df_transacciones_landing.printSchema()\n","\n","#13.4 Mostrar los datos del dataframe\n","df_transacciones_landing.show(5)\n","\n","#13.7 Definir ruta de curated\n","\n","#Archivo en Cloud Storage - Google Cloud Platform\n","ruta_transacciones_curated = \"gs://curso-apache-spark/datalake/curated/transacciones/\"\n","\n","#Archivo DBFS - DataBricks\n","# ruta_transacciones_curated = \"/FileStore/tables/curated/transacciones/\"\n","\n","#Archivo en HDFS - Hadoop\n","#ruta_transacciones_curated = \"hdfs:/introduccion-apache-spark/datalake/curated/transacciones/\"\n","\n","# 13.8 Guardar daframe en capa curated\n","\n","df_transacciones_landing.write.mode(\"overwrite\").format(\"parquet\").partitionBy(\"FECHA\").save(ruta_transacciones_curated)"]},{"cell_type":"code","execution_count":null,"id":"67b8d7dc","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":5}